{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ea282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BigQuery client library (run this cell once)\n",
    "%pip install google-cloud-bigquery --quiet\n",
    "%pip install bigquery-magics --quiet\n",
    "%pip install db-dtypes --quiet\n",
    "# Import libraries\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "%load_ext bigquery_magics\n",
    "import db_dtypes\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"salesforce-465614-2cf9e37da64b.json\"\n",
    "from google.cloud import bigquery\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b2a35",
   "metadata": {},
   "source": [
    "<b>Truncate Stage tables before loading from CSV's</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e529e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aa826df43649459bb103fa2e88b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bqsql\n",
    "truncate table salesforce-465614.cust_analytics.stage_transactions;\n",
    "truncate table salesforce-465614.cust_analytics.stage_customers;\n",
    "truncate table salesforce-465614.cust_analytics.stage_products;\n",
    "truncate table salesforce-465614.cust_analytics.stage_stores;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20be8b",
   "metadata": {},
   "source": [
    "<b>Entry in ETL Job Monitoring table</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d377ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_11248\\1991522017.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  job_run_date = datetime.utcnow().date()\n",
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_11248\\1991522017.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  start_time = datetime.utcnow()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x24807336720>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set monitoring table and module name\n",
    "monitoring_table = \"salesforce-465614.cust_analytics.etl_job_monitoring\"\n",
    "module_name = \"File to Stage Layer\"\n",
    "job_run_date = datetime.utcnow().date()\n",
    "start_time = datetime.utcnow()\n",
    "# Insert start record\n",
    "insert_start = f\"\"\"\n",
    "INSERT INTO `{monitoring_table}` (job_run_date, module_name, start_time, status)\n",
    "VALUES (DATE('{job_run_date}'), '{module_name}', TIMESTAMP('{start_time}'), 'Running')\n",
    "\"\"\"\n",
    "client.query(insert_start).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db25d6",
   "metadata": {},
   "source": [
    "<b>Loading Stage Tables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Transactions.csv to salesforce-465614.cust_analytics.stage_transactions\n",
      "Loaded Customer.csv to salesforce-465614.cust_analytics.stage_customers\n",
      "Loaded Product.csv to salesforce-465614.cust_analytics.stage_products\n",
      "Loaded Store.csv to salesforce-465614.cust_analytics.stage_stores\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "# Define dataset and table names\n",
    "dataset_id = \"cust_analytics\"  \n",
    "file_path = \"v2/\"\n",
    "# Mapping of file names to table names\n",
    "# \"DimCustomer.csv\": \"stage_customers\",\n",
    "# \"DimProduct.csv\": \"stage_products\",\n",
    "# \"DimStore.csv\": \"stage_stores\"\n",
    "file_table_map = {\n",
    "    \"Transactions.csv\": \"stage_transactions\",\n",
    "    \"Customer.csv\": \"stage_customers\",\n",
    "    \"Product.csv\": \"stage_products\",\n",
    "    \"Store.csv\": \"stage_stores\"\n",
    "}\n",
    "\n",
    "# Load each CSV into its respective BigQuery table\n",
    "for file_name, table_name in file_table_map.items():\n",
    "    table_id = f\"{client.project}.{dataset_id}.{table_name}\"\n",
    "    full_file_path = os.path.join(file_path, file_name)\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    )\n",
    "    with open(full_file_path, \"rb\") as source_file:\n",
    "        load_job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "    load_job.result()  # Wait for the job to complete\n",
    "    print(f\"Loaded {file_name} to {table_id}\")\n",
    "try:\n",
    "    end_time = datetime.utcnow()\n",
    "    update_success = f\"\"\"\n",
    "    UPDATE `{monitoring_table}`\n",
    "    SET end_time = TIMESTAMP('{end_time}'), status = 'Success'\n",
    "    WHERE job_run_date = DATE('{job_run_date}') AND module_name = '{module_name}' AND start_time = TIMESTAMP('{start_time}')\n",
    "    \"\"\"\n",
    "    client.query(update_success).result()\n",
    "except Exception as e:\n",
    "    # Update status as Failed\n",
    "    fail_time = datetime.utcnow()\n",
    "    update_failed = f\"\"\"\n",
    "    UPDATE `{monitoring_table}`\n",
    "    SET end_time = TIMESTAMP('{fail_time}'), status = 'Failed'\n",
    "    WHERE job_run_date = DATE('{job_run_date}') AND module_name = '{module_name}' AND start_time = TIMESTAMP('{start_time}')\n",
    "    \"\"\"\n",
    "    client.query(update_failed).result()\n",
    "    print(\"ETL job failed:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad14ff",
   "metadata": {},
   "source": [
    "<b>Data Cleaning before loading to Persistant Tables</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377b3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not-null counts for stage_customers:\n",
      "customer_id        2000\n",
      "first_name         2000\n",
      "last_name          2000\n",
      "gender             2000\n",
      "age                2000\n",
      "signup_date        2000\n",
      "loyalty_program    2000\n",
      "email              2000\n",
      "city               2000\n",
      "state              2000\n",
      "country            2000\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Not-null counts for stage_products:\n",
      "product_id      200\n",
      "product_name    200\n",
      "category        200\n",
      "sub_category    200\n",
      "price           200\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Not-null counts for stage_transactions:\n",
      "Transaction_id    20000\n",
      "Customer_ID       20000\n",
      "Product_id        20000\n",
      "Store_Location    20000\n",
      "Purchase_Date     20000\n",
      "Product_Type      20000\n",
      "Unit_Price        20000\n",
      "Quantity          20000\n",
      "Total_Price       20000\n",
      "Payment_Method    20000\n",
      "Channel           20000\n",
      "Order_Status      20000\n",
      "Loyalty_Member    20000\n",
      "Age               20000\n",
      "Gender            20000\n",
      "City              20000\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Not-null counts for stage_stores:\n",
      "string_field_0    50\n",
      "string_field_1    50\n",
      "string_field_2    32\n",
      "string_field_3    50\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of stage tables to check\n",
    "stage_tables = [\n",
    "    \"stage_customers\",\n",
    "    \"stage_products\",\n",
    "    \"stage_transactions\",\n",
    "    \"stage_stores\"\n",
    "]\n",
    "# Dictionary to store not-null counts for each table\n",
    "not_null_counts_dict = {}\n",
    "for table in stage_tables:\n",
    "    query = f\"SELECT * FROM `{client.project}.{dataset_id}.{table}`\"\n",
    "    df = client.query(query).to_dataframe()\n",
    "    not_null_counts_dict[table] = df.notnull().sum()\n",
    "# Display not-null counts for each table\n",
    "for table, counts in not_null_counts_dict.items():\n",
    "    print(f\"Not-null counts for {table}:\")\n",
    "    print(counts)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to delete duplicates in each stage table based on all columns\n",
    "\n",
    "stage_tables = [\n",
    "    \"stage_customers\",\n",
    "    \"stage_products\",\n",
    "    \"stage_transactions\",\n",
    "    \"stage_stores\"\n",
    "]\n",
    "\n",
    "for table in stage_tables:\n",
    "    # Get column names for the table\n",
    "    table_ref = f\"{client.project}.{dataset_id}.{table}\"\n",
    "    schema = client.get_table(table_ref).schema\n",
    "    columns = [field.name for field in schema]\n",
    "    # Build partition columns (all columns except row_number)\n",
    "    col_list = \", \".join(columns)\n",
    "    # Build delete query using row_number window function\n",
    "    delete_duplicates_query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_ref}` AS\n",
    "    SELECT * EXCEPT(row_num) FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER (PARTITION BY {col_list}) as row_num\n",
    "        FROM `{table_ref}`\n",
    "    )\n",
    "    WHERE row_num = 1\n",
    "    \"\"\"\n",
    "    client.query(delete_duplicates_query).result()\n",
    "    print(f\"Duplicates removed from {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64ed73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
